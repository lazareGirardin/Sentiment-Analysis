{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_f = './Data/train.tsv'\n",
    "train = pd.DataFrame.from_csv(tr_f, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>This</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2</td>\n",
       "      <td>quiet , introspective and entertaining indepen...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>quiet , introspective and entertaining</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2</td>\n",
       "      <td>quiet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>, introspective and entertaining</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>introspective and entertaining</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "      <td>introspective and</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>introspective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>independent</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2</td>\n",
       "      <td>is worth seeking .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>is worth seeking</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>is worth</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>worth</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>seeking</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "64                 2  This quiet , introspective and entertaining in...   \n",
       "65                 2  This quiet , introspective and entertaining in...   \n",
       "66                 2                                               This   \n",
       "67                 2  quiet , introspective and entertaining indepen...   \n",
       "68                 2             quiet , introspective and entertaining   \n",
       "69                 2                                              quiet   \n",
       "70                 2                   , introspective and entertaining   \n",
       "71                 2                     introspective and entertaining   \n",
       "72                 2                                  introspective and   \n",
       "73                 2                                      introspective   \n",
       "74                 2                                                and   \n",
       "75                 2                                       entertaining   \n",
       "76                 2                                        independent   \n",
       "77                 2                                 is worth seeking .   \n",
       "78                 2                                   is worth seeking   \n",
       "79                 2                                           is worth   \n",
       "80                 2                                              worth   \n",
       "81                 2                                            seeking   \n",
       "\n",
       "          Sentiment  \n",
       "PhraseId             \n",
       "64                4  \n",
       "65                3  \n",
       "66                2  \n",
       "67                4  \n",
       "68                3  \n",
       "69                2  \n",
       "70                3  \n",
       "71                3  \n",
       "72                3  \n",
       "73                2  \n",
       "74                2  \n",
       "75                4  \n",
       "76                2  \n",
       "77                3  \n",
       "78                4  \n",
       "79                2  \n",
       "80                2  \n",
       "81                2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.SentenceId == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#english_sw = stopwords.words('english')\n",
    "english_sw = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def tokenize_stopwords(df):\n",
    "    # Tokenize and remove punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(df['Phrase'])\n",
    "    #tokens = nltk.word_tokenize(df['Phrase'])\n",
    "    return [t.lower() for t in tokens if t.lower() not in (english_sw + ['rrb', 'lrb'])] \n",
    "\n",
    "def keep_first(group):\n",
    "    return pd.Series({\"Phrase\": group[\"Phrase\"].iloc[0], \"Sentiment\": group[\"Sentiment\"].iloc[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keep only first  full sentence\n",
    "full = train.copy()\n",
    "#full = full.groupby(\"SentenceId\").apply(keep_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment  \n",
       "PhraseId             \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "5                 2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full['Phrase tokenized'] = full.apply(tokenize_stopwords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>[a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment                                   Phrase tokenized  \n",
       "PhraseId                                                                \n",
       "1                 1  [a, series, of, escapades, demonstrating, the,...  \n",
       "2                 2  [a, series, of, escapades, demonstrating, the,...  \n",
       "3                 2                                        [a, series]  \n",
       "4                 2                                                [a]  \n",
       "5                 2                                           [series]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId\n",
       "61                                           [a, story]\n",
       "62                                              [story]\n",
       "63                                                   []\n",
       "64    [this, quiet, introspective, and, entertaining...\n",
       "65    [this, quiet, introspective, and, entertaining...\n",
       "66                                               [this]\n",
       "67    [quiet, introspective, and, entertaining, inde...\n",
       "68            [quiet, introspective, and, entertaining]\n",
       "69                                              [quiet]\n",
       "70                   [introspective, and, entertaining]\n",
       "Name: Phrase tokenized, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['Phrase tokenized'].iloc[60:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of unique words in the the most frequent order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create unique list\n",
    "uniques = []\n",
    "for i in range(full.shape[0]):\n",
    "    for word in full['Phrase tokenized'].iloc[i]:\n",
    "        if word not in uniques:\n",
    "            uniques.append(word)\n",
    "print(len(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create count list\n",
    "# PLIZ DON'T DO THIS!!!\n",
    "counts = []\n",
    "for unique in uniques:\n",
    "    count = 0              # Initialize the count to zero.\n",
    "    for i in range(full.shape[0]):\n",
    "        for word in full['Phrase tokenized'].iloc[i]:     # Iterate over the words.\n",
    "            if word == unique:   # Is this word equal to the current unique?\n",
    "                count += 1         # If so, increment the count\n",
    "    counts.append((count, unique))\n",
    "    \n",
    "counts.sort()\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "words = []\n",
    "for i in range(full.shape[0]):\n",
    "    for word in full['Phrase tokenized'].iloc[i]:\n",
    "        words.append(word)\n",
    "dic1 = Counter(words)\n",
    "print(len(dic1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_words = sorted(dic1.items(), key=operator.itemgetter(1), reverse=True)\n",
    "#print(sorted_words)\n",
    "maxDictLength = len(dic1)\n",
    "word_dict = dict([ (sorted_words[i][0], i+2)for i in range(maxDictLength)])\n",
    "#print(word_dictionary)\n",
    "#sorted_dic = sorted(word_dictionary.items(), key=operator.itemgetter(1))\n",
    "#print(sorted_dic)\n",
    "oovf = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def words_to_dict(row):\n",
    "    return [[word_dict[r] if (r in word_dict) else oovf] for r in row[\"Phrase tokenized\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full[\"Dict values\"] = full.apply(words_to_dict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(full[\"Dict values\"].iloc[65])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a stemmer on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def stemmer(row):\n",
    "    eng_stemmer = SnowballStemmer('english')\n",
    "    return [eng_stemmer.stem(word) for word in row[\"Phrase tokenized\"]]\n",
    "\n",
    "def lem_words(row):\n",
    "    w_lemmatizer = WordNetLemmatizer()\n",
    "    return [(w_lemmatizer.lemmatize(word, tag) if tag else w_lemmatizer.lemmatize(word)) for (word,tag) in row[\"PoS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full[\"stemmed\"] = full.apply(stemmer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase tokenized</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[a, seri, of, escapad, demonstr, the, adag, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[a, seri, of, escapad, demonstr, the, adag, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, series]</td>\n",
       "      <td>[a, seri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>[a]</td>\n",
       "      <td>[a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[seri]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment                                   Phrase tokenized  \\\n",
       "PhraseId                                                                 \n",
       "1                 1  [a, series, of, escapades, demonstrating, the,...   \n",
       "2                 2  [a, series, of, escapades, demonstrating, the,...   \n",
       "3                 2                                        [a, series]   \n",
       "4                 2                                                [a]   \n",
       "5                 2                                           [series]   \n",
       "\n",
       "                                                    stemmed  \n",
       "PhraseId                                                     \n",
       "1         [a, seri, of, escapad, demonstr, the, adag, th...  \n",
       "2         [a, seri, of, escapad, demonstr, the, adag, th...  \n",
       "3                                                 [a, seri]  \n",
       "4                                                       [a]  \n",
       "5                                                    [seri]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def is_noun(tag):\n",
    "    return tag in ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "\n",
    "def is_verb(tag):\n",
    "    return tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "\n",
    "def is_adverb(tag):\n",
    "    return tag in ['RB', 'RBR', 'RBS']\n",
    "\n",
    "\n",
    "def is_adjective(tag):\n",
    "    return tag in ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if is_adjective(tag):\n",
    "        return wn.ADJ\n",
    "    elif is_noun(tag):\n",
    "        return wn.NOUN\n",
    "    elif is_adverb(tag):\n",
    "        return wn.ADV\n",
    "    elif is_verb(tag):\n",
    "        return wn.VERB\n",
    "    return None\n",
    "\n",
    "def pos_tagging(df):\n",
    "    pos_tags = nltk.pos_tag(df[\"Phrase tokenized\"])\n",
    "    return [(PoS[0], penn_to_wn(PoS[1])) for PoS in pos_tags] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase tokenized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>PoS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[a, seri, of, escapad, demonstr, the, adag, th...</td>\n",
       "      <td>[(a, None), (series, n), (of, None), (escapade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[a, seri, of, escapad, demonstr, the, adag, th...</td>\n",
       "      <td>[(a, None), (series, n), (of, None), (escapade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, series]</td>\n",
       "      <td>[a, seri]</td>\n",
       "      <td>[(a, None), (series, n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>[a]</td>\n",
       "      <td>[a]</td>\n",
       "      <td>[(a, None)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[seri]</td>\n",
       "      <td>[(series, n)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment                                   Phrase tokenized  \\\n",
       "PhraseId                                                                 \n",
       "1                 1  [a, series, of, escapades, demonstrating, the,...   \n",
       "2                 2  [a, series, of, escapades, demonstrating, the,...   \n",
       "3                 2                                        [a, series]   \n",
       "4                 2                                                [a]   \n",
       "5                 2                                           [series]   \n",
       "\n",
       "                                                    stemmed  \\\n",
       "PhraseId                                                      \n",
       "1         [a, seri, of, escapad, demonstr, the, adag, th...   \n",
       "2         [a, seri, of, escapad, demonstr, the, adag, th...   \n",
       "3                                                 [a, seri]   \n",
       "4                                                       [a]   \n",
       "5                                                    [seri]   \n",
       "\n",
       "                                                        PoS  \n",
       "PhraseId                                                     \n",
       "1         [(a, None), (series, n), (of, None), (escapade...  \n",
       "2         [(a, None), (series, n), (of, None), (escapade...  \n",
       "3                                  [(a, None), (series, n)]  \n",
       "4                                               [(a, None)]  \n",
       "5                                             [(series, n)]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full[\"PoS\"] = full.apply(pos_tagging, axis=1)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full[\"lemmatized\"] = full.apply(lem_words, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId\n",
       "1    [a, series, of, escapade, demonstrate, the, ad...\n",
       "2    [a, series, of, escapade, demonstrate, the, ad...\n",
       "3                                          [a, series]\n",
       "4                                                  [a]\n",
       "5                                             [series]\n",
       "Name: lemmatized, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['lemmatized'].iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceId                                                          1\n",
       "Phrase              A series of escapades demonstrating the adage ...\n",
       "Sentiment                                                           2\n",
       "Phrase tokenized    [a, series, of, escapades, demonstrating, the,...\n",
       "stemmed             [a, seri, of, escapad, demonstr, the, adag, th...\n",
       "PoS                 [(a, None), (series, n), (of, None), (escapade...\n",
       "lemmatized          [a, series, of, escapade, demonstrate, the, ad...\n",
       "Dict values         [[3], [337], [4], [6122], [1408], [2], [5914],...\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13467\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "words = []\n",
    "for i in range(full.shape[0]):\n",
    "    for word in full['lemmatized'].iloc[i]:\n",
    "        words.append(word)\n",
    "counts = Counter(words)\n",
    "print(len(counts))\n",
    "\n",
    "OoV = 1\n",
    "# Total extra char used\n",
    "nb_extraChar = 2\n",
    "max_words = 10000\n",
    "maxDictLength = max_words - nb_extraChar\n",
    "\n",
    "sorted_words = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "word_dict = dict([ (sorted_words[i][0], i+nb_extraChar)for i in range(maxDictLength)])\n",
    "\n",
    "def words_to_dict(row):\n",
    "    return [[word_dict[r] if (r in word_dict) else OoV] for r in row['lemmatized']]\n",
    "\n",
    "# X and Y corresponds to the dictionnary values and Sentiment values\n",
    "full[\"Dict values\"] = full.apply(words_to_dict, axis=1)\n",
    "x = np.array(full[\"Dict values\"])\n",
    "y = np.array(full[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "x = sequence.pad_sequences(x, 30)\n",
    "x = x.reshape((x.shape[0], x.shape[1]))\n",
    "\n",
    "min_length = min(len(x[y==0]), len(x[y==1]), len(x[y==2]), len(x[y==3]), len(x[y==4]))\n",
    "print(min_length)\n",
    "\n",
    "idx = np.random.permutation(np.arange(min_length))\n",
    "\n",
    "tr_ratio = 0.8\n",
    "tr_l = int(tr_ratio*min_length)\n",
    "x_train = np.zeros((x.shape[1]))\n",
    "for i in range(5):\n",
    "    idx = np.random.permutation(np.arange(min_length))\n",
    "    x_train_temp = x[y==i][idx[:tr_l]]\n",
    "    x_test_temp = x[y==i][idx[tr_l:]]\n",
    "    y_train_temp = y[y==i][idx[:tr_l]]\n",
    "    y_test_temp = y[y==i][idx[tr_l:]]\n",
    "    x_train = np.vstack((x_train, x_train_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   101],\n",
       "       [   103],\n",
       "       [   157],\n",
       "       ..., \n",
       "       [155970],\n",
       "       [155971],\n",
       "       [155973]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46655\n",
      "[[     1]\n",
      " [     2]\n",
      " [     3]\n",
      " ..., \n",
      " [156055]\n",
      " [156058]\n",
      " [156059]]\n",
      "[[127810]\n",
      " [138758]\n",
      " [ 21646]\n",
      " ..., \n",
      " [ 51183]\n",
      " [ 48928]\n",
      " [ 17063]]\n",
      "7072 27273 32927 32927 9206\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "x = sequence.pad_sequences(x, 30)\n",
    "x = x.reshape((x.shape[0], x.shape[1]))\n",
    "\n",
    "to_remove = len(x[y==2]) - len(x[y==3])\n",
    "print(to_remove)\n",
    "\n",
    "ind_class3 = np.argwhere(y==2)\n",
    "\n",
    "print(ind_class3)\n",
    "\n",
    "ind_rm = np.random.permutation(ind_class3)\n",
    "\n",
    "print(ind_rm)\n",
    "\n",
    "x_rm = np.delete(x, ind_rm[:to_remove], 0)\n",
    "y_rm = np.delete(y, ind_rm[:to_remove], 0)\n",
    "\n",
    "print(len(x_rm[y_rm==0]), len(x_rm[y_rm==1]), len(x_rm[y_rm==2]), len(x_rm[y_rm==3]), len(x_rm[y_rm==4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.41346154  1.14442856  0.39219924  0.94791508  3.39039757]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_w = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "print(class_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array(full[\"Dict values\"])\n",
    "y = np.array(full[\"Sentiment\"])\n",
    "\n",
    "# Binary class\n",
    "y[y<=2]=0\n",
    "y[y>2]=1\n",
    "\n",
    "y_2 = np.array(full.Sentiment >=3)\n",
    "\n",
    "print(sum(y!=y_2))\n",
    "\n",
    "t_ratio = 0.8\n",
    "tr_length = int(t_ratio*x.shape[0])\n",
    "\n",
    "# Add randomization here\n",
    "x_train = x[:tr_length]\n",
    "x_test = x[tr_length:]\n",
    "y_train = x[:tr_length]\n",
    "y_test = x[tr_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full[full.Sentiment == 2][\"Phrase\"].iloc[:10].apply(lambda x: print(\"\\n\"+x))\n",
    "\n",
    "#print(\"-------------------------------------------\")\n",
    "#full[full.Sentiment == 3][\"Phrase\"].iloc[:5].apply(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratios = full.groupby('Sentiment').count()\n",
    "ratios.drop(['Phrase'], axis=1, inplace = True)\n",
    "ratios.columns = ['Count']\n",
    "ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full[\"Logical Sentiment\"] = full.Sentiment >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
