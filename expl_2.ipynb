{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_f = './Data/train.tsv'\n",
    "train = pd.DataFrame.from_csv(tr_f, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>This</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2</td>\n",
       "      <td>quiet , introspective and entertaining indepen...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>quiet , introspective and entertaining</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2</td>\n",
       "      <td>quiet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>, introspective and entertaining</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>introspective and entertaining</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "      <td>introspective and</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>introspective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>independent</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2</td>\n",
       "      <td>is worth seeking .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>is worth seeking</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>is worth</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>worth</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>seeking</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "64                 2  This quiet , introspective and entertaining in...   \n",
       "65                 2  This quiet , introspective and entertaining in...   \n",
       "66                 2                                               This   \n",
       "67                 2  quiet , introspective and entertaining indepen...   \n",
       "68                 2             quiet , introspective and entertaining   \n",
       "69                 2                                              quiet   \n",
       "70                 2                   , introspective and entertaining   \n",
       "71                 2                     introspective and entertaining   \n",
       "72                 2                                  introspective and   \n",
       "73                 2                                      introspective   \n",
       "74                 2                                                and   \n",
       "75                 2                                       entertaining   \n",
       "76                 2                                        independent   \n",
       "77                 2                                 is worth seeking .   \n",
       "78                 2                                   is worth seeking   \n",
       "79                 2                                           is worth   \n",
       "80                 2                                              worth   \n",
       "81                 2                                            seeking   \n",
       "\n",
       "          Sentiment  \n",
       "PhraseId             \n",
       "64                4  \n",
       "65                3  \n",
       "66                2  \n",
       "67                4  \n",
       "68                3  \n",
       "69                2  \n",
       "70                3  \n",
       "71                3  \n",
       "72                3  \n",
       "73                2  \n",
       "74                2  \n",
       "75                4  \n",
       "76                2  \n",
       "77                3  \n",
       "78                4  \n",
       "79                2  \n",
       "80                2  \n",
       "81                2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.SentenceId == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def tokenize_stopwords(df):\n",
    "    # Tokenize and remove punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(df['Phrase'])\n",
    "    #tokens = nltk.word_tokenize(df['Phrase'])\n",
    "    return [t.lower() for t in tokens if t.lower() not in (english_sw + ['rrb', 'lrb'])] \n",
    "\n",
    "def keep_first(group):\n",
    "    return pd.Series({\"Phrase\": group[\"Phrase\"].iloc[0], \"Sentiment\": group[\"Sentiment\"].iloc[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keep only first  full sentence\n",
    "full = train.copy()\n",
    "full = full.groupby(\"SentenceId\").apply(keep_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SentenceId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Phrase  Sentiment\n",
       "SentenceId                                                              \n",
       "1           A series of escapades demonstrating the adage ...          1\n",
       "2           This quiet , introspective and entertaining in...          4\n",
       "3           Even fans of Ismail Merchant 's work , I suspe...          1\n",
       "4           A positively thrilling combination of ethnogra...          3\n",
       "5           Aggressive self-glorification and a manipulati...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full['Phrase tokenized'] = full.apply(tokenize_stopwords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SentenceId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "      <td>[quiet, introspective, entertaining, independe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[even, fans, ismail, merchant, work, suspect, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "      <td>[positively, thrilling, combination, ethnograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "      <td>[aggressive, self, glorification, manipulative...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Phrase  Sentiment  \\\n",
       "SentenceId                                                                 \n",
       "1           A series of escapades demonstrating the adage ...          1   \n",
       "2           This quiet , introspective and entertaining in...          4   \n",
       "3           Even fans of Ismail Merchant 's work , I suspe...          1   \n",
       "4           A positively thrilling combination of ethnogra...          3   \n",
       "5           Aggressive self-glorification and a manipulati...          1   \n",
       "\n",
       "                                             Phrase tokenized  \n",
       "SentenceId                                                     \n",
       "1           [series, escapades, demonstrating, adage, good...  \n",
       "2           [quiet, introspective, entertaining, independe...  \n",
       "3           [even, fans, ismail, merchant, work, suspect, ...  \n",
       "4           [positively, thrilling, combination, ethnograp...  \n",
       "5           [aggressive, self, glorification, manipulative...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['series',\n",
       " 'escapades',\n",
       " 'demonstrating',\n",
       " 'adage',\n",
       " 'good',\n",
       " 'goose',\n",
       " 'also',\n",
       " 'good',\n",
       " 'gander',\n",
       " 'occasionally',\n",
       " 'amuses',\n",
       " 'none',\n",
       " 'amounts',\n",
       " 'much',\n",
       " 'story']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['Phrase tokenized'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of unique words in the the most frequent order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15065\n"
     ]
    }
   ],
   "source": [
    "# Create unique list\n",
    "uniques = []\n",
    "for i in range(full.shape[0]):\n",
    "    for word in full['Phrase tokenized'].iloc[i]:\n",
    "        if word not in uniques:\n",
    "            uniques.append(word)\n",
    "print(len(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create count list\n",
    "# PLIZ DON'T DO THIS!!!\n",
    "counts = []\n",
    "for unique in uniques:\n",
    "    count = 0              # Initialize the count to zero.\n",
    "    for i in range(full.shape[0]):\n",
    "        for word in full['Phrase tokenized'].iloc[i]:     # Iterate over the words.\n",
    "            if word == unique:   # Is this word equal to the current unique?\n",
    "                count += 1         # If so, increment the count\n",
    "    counts.append((count, unique))\n",
    "    \n",
    "counts.sort()\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15065\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = []\n",
    "for i in range(full.shape[0]):\n",
    "    for word in full['Phrase tokenized'].iloc[i]:\n",
    "        words.append(word)\n",
    "dic1 = Counter(words)\n",
    "print(len(dic1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_words = sorted(dic1.items(), key=operator.itemgetter(1), reverse=True)\n",
    "#print(sorted_words)\n",
    "maxDictLength = len(dic1)\n",
    "word_dict = dict([ (sorted_words[i][0], i+3)for i in range(maxDictLength)])\n",
    "#print(word_dictionary)\n",
    "#sorted_dic = sorted(word_dictionary.items(), key=operator.itemgetter(1))\n",
    "#print(sorted_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def words_to_dict(row):\n",
    "    return [word_dict[r] for r in row[\"Phrase tokenized\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full[\"Dict values\"] = full.apply(words_to_dict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase tokenized</th>\n",
       "      <th>Dict values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SentenceId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[217, 9501, 5158, 4390, 6, 3427, 55, 6, 10700,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "      <td>[quiet, introspective, entertaining, independe...</td>\n",
       "      <td>[551, 4992, 90, 3258, 116, 1947]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[even, fans, ismail, merchant, work, suspect, ...</td>\n",
       "      <td>[9, 191, 10161, 2433, 23, 2751, 19, 67, 10, 87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "      <td>[positively, thrilling, combination, ethnograp...</td>\n",
       "      <td>[2827, 3727, 1277, 11224, 1289, 3813, 13408, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "      <td>[aggressive, self, glorification, manipulative...</td>\n",
       "      <td>[4674, 68, 7383, 905, 8581]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Phrase  Sentiment  \\\n",
       "SentenceId                                                                 \n",
       "1           A series of escapades demonstrating the adage ...          1   \n",
       "2           This quiet , introspective and entertaining in...          4   \n",
       "3           Even fans of Ismail Merchant 's work , I suspe...          1   \n",
       "4           A positively thrilling combination of ethnogra...          3   \n",
       "5           Aggressive self-glorification and a manipulati...          1   \n",
       "\n",
       "                                             Phrase tokenized  \\\n",
       "SentenceId                                                      \n",
       "1           [series, escapades, demonstrating, adage, good...   \n",
       "2           [quiet, introspective, entertaining, independe...   \n",
       "3           [even, fans, ismail, merchant, work, suspect, ...   \n",
       "4           [positively, thrilling, combination, ethnograp...   \n",
       "5           [aggressive, self, glorification, manipulative...   \n",
       "\n",
       "                                                  Dict values  \n",
       "SentenceId                                                     \n",
       "1           [217, 9501, 5158, 4390, 6, 3427, 55, 6, 10700,...  \n",
       "2                            [551, 4992, 90, 3258, 116, 1947]  \n",
       "3           [9, 191, 10161, 2433, 23, 2751, 19, 67, 10, 87...  \n",
       "4           [2827, 3727, 1277, 11224, 1289, 3813, 13408, 6...  \n",
       "5                                 [4674, 68, 7383, 905, 8581]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full[full.Sentiment == 2][\"Phrase\"].iloc[:10].apply(lambda x: print(\"\\n\"+x))\n",
    "\n",
    "#print(\"-------------------------------------------\")\n",
    "#full[full.Sentiment == 3][\"Phrase\"].iloc[:5].apply(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratios = full.groupby('Sentiment').count()\n",
    "ratios.drop(['Phrase'], axis=1, inplace = True)\n",
    "ratios.columns = ['Count']\n",
    "ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full[\"Logical Sentiment\"] = full.Sentiment >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
